{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor notes - part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. \n",
    "\n",
    "```\n",
    "cd Desktop\n",
    "source activate py3\n",
    "jupyter lab\n",
    "```\n",
    "\n",
    "2. Code inspector: `CTRL-i`\n",
    "\n",
    "3. DON'T SCROLL FAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "1. Introduce self\n",
    "2. We saw some examples of plotting yesterday morning, and that's primarily what we'll be talking about today. \n",
    "3. A side note: in my own research I mostly use **numpy** for data analysis, since most of my data is purely numerical, but I have found pandas to be extremely useful anytime any text is involved in my data. It's still hard for me to understand some of the things pandas can do, but what you'll realize is that many things that would be complicated to implement step-by-step are already built in to pandas.\n",
    "\n",
    "## Recap from yesterday:\n",
    "\n",
    "1. Python is an awesome general-purpose programming language, very popular for lots of uses from web development to data science. \n",
    "2. Code for this morning's section is linked on the website, it's part 3: https://github.com/UofTCoders/2018-07-12-utoronto/blob/gh-pages/code/3-data-wrangling-and-viz.ipynb\n",
    "3. Yesterday you were introduced to the Jupyter Lab environment, the syntax of the Python language, and how to work with spreadsheet-like data using pandas. \n",
    "4. To recap, here are a few of the things that were covered:\n",
    "\n",
    "  - slicing inside lists: \n",
    "```\n",
    "data = [3.5, 2, 8, -4]\n",
    "data[0:3] # get the first three elements\n",
    "data[:2] # get the first two elements\n",
    "data[-1] # get the last element\n",
    "data[-3:] # get the last 3 elements\n",
    "data[-1] = -5 # reassign an element in a list\n",
    "```\n",
    "  - using `if` to do conditional logic:\n",
    "    ```\n",
    "    my_name = \"Madeleine Bonsma-Fisher\"\n",
    "    if len(my_name) > 20:\n",
    "        print(\"This name used to be too long for a Twitter name\")\n",
    "    elif len(my_name) > 50:\n",
    "        print(\"This name is too long for a Twitter name\")\n",
    "    else:\n",
    "        print(\"This name is not too long for Twitter\")\n",
    "    ```\n",
    "  - importing specific packages:\n",
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "```\n",
    "  - loading data as a `pandas` data frame:\n",
    "```\n",
    "surveys = pd.read_csv(\"https://ndownloader.figshare.com/files/2292169\")\n",
    "# or surveys = pd.read_csv(\"surveys.csv\")\n",
    "```\n",
    "  - using `pandas` builtin functions to get a quick idea of our data:\n",
    "```\n",
    "surveys.info()\n",
    "surveys.describe()\n",
    "surveys.columns\n",
    "```\n",
    "   Which things have parentheses and which don't is kind of subtle, but Francis described it well: anything with parentheses is a *function* which is executing some code under the hood (also called a *method* in this context), and often there are optional parameters you can give it (like `n` for `.head()`). Anything without parentheses is an *attribute* - it's a feature of the object that is available to access without doing any additional work in the background.\n",
    "  - selecting rows and columns from `pandas` data frames:\n",
    "```\n",
    "surveys[['weight', 'hindfoot_length]] # getting one or a few columns\n",
    "surveys.loc[0]  # select rows or rows and columns, uses square brackets and the syntax is [[row slice], [column slice]]\n",
    "surveys.loc[[0,4,5],['weight', 'species']]\n",
    "surveys.loc[:,'weight':'species'] # get all the rows for columns weight to species (this slice is INCLUSIVE on both ends)\n",
    "surveys.iloc[:, 3:6] # .iloc is the same as .loc except that it takes a numerical index instead of the true row or column label\n",
    "surveys.iloc[-10:] # CAN ANYONE TELL ME another command that would have given us the exact same result here?\n",
    "```\n",
    "  - using comparison operators to select rows and columns matching a condition\n",
    "```\n",
    "surveys.loc[(surveys['taxa'] == 'Rodent') &\n",
    "            (surveys['sex'] == 'F'),\n",
    "            ['taxa', 'sex']].head()\n",
    "```\n",
    "  - using `groupby` to perform analysis by splitting data into categorical variables\n",
    "```\n",
    "import numpy as np\n",
    "grouped_surveys = surveys.groupby(['species', 'sex'])\n",
    "grouped_surveys['weight'].agg(np.mean)\n",
    "grouped_surveys.size()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to data vis in matplotlib and seaborn\n",
    "\n",
    "- It's possible to make a ton of visualizations in Python - show examples in galleries\n",
    "- Here, we will focus on two of the most useful for researchers, `matplotlib` which is a robust, detail-oriented, low level plotting interface, and `seaborn` which provides high level functions on top of `matplotlib` and allows the plotting calls to be expressed more in terms what is being explored in the underlying data rather than what graphical elements to add to the plot.\n",
    "- I use `matplotlib` pretty heavily and that's what I'm used to, and I'm pretty new to `seaborn`, so if there's anything that doesn't make sense to you it probably also doesn't make sense to me, and please feel free to bring it up so we can figure it out together.\n",
    "- The idea behind `seaborn` is that instead of instructing the computer to \"go through a data frame and plot any observations of speciesX in blue, any observations of speciesY in red, etc\", the `seaborn` syntax is more similar to saying \"color the data by species\". \n",
    "- Another way to think about it: if you have spreadsheet-like data with one or more categorial variables (like `species`), seaborn is probably going to be super useful. If your data is exclusively numerical, `matplotlib` might be more natural.\n",
    "- In `seaborn`, only minimal changes are required if the underlying data change or to switch the type of plot used for the visualization. It provides a language that facilitates thinking about data in ways that are conducive for exploratory analysis and allows for the and creation of publication quality plots with minimal amounts of adjustments and tweaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Challenge\n",
    ">\n",
    ">1. Create a violin plot of species vs weight, split down the middle by sex.\n",
    ">2. (Bonus) add the fifth and sixth most-common species to the plot. \n",
    "\n",
    "```\n",
    "1. sns.violinplot(x='weight', y='species', hue='sex', data=surveys_common, split=True)\n",
    "2.\n",
    "most_common_species2 = (\n",
    "    surveys['species']\n",
    "       .value_counts()\n",
    "       .nlargest(6)\n",
    "       .index\n",
    ")\n",
    "surveys_common2 = surveys.loc[surveys['species'].isin(most_common_species2)].shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
